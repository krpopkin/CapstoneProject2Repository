{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook \n",
    "\n",
    "#### Feature: Description\n",
    "\n",
    "This notebook employs Word2Vec with CountVectorizer to create a training and test dataset of the pet description field.  Then the datasets are used in the XGBoost algorithm to create an adoption model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Feature Description: </I> The \"Description\" data is a profile write-up for each pet.\n",
    "     <br>\n",
    "    <I> Source: </I> https://www.kaggle.com/c/petfinder-adoption-prediction/data  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Predictor (Adoption Speed) Description: </I> \n",
    "\n",
    "Contestants are required to predict this value. The value is determined by how quickly, if at all, a pet is adopted.   \n",
    "<br> \n",
    "The values are determined in the following way:   \n",
    "0 - Pet was adopted on the same day as it was listed.    \n",
    "1 - Pet was adopted between 1 and 7 days (1st week) after being listed.    \n",
    "2 - Pet was adopted between 8 and 30 days (1st month) after being listed.    \n",
    "3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.    \n",
    "4 - No adoption after 100 days of being listed.    \n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Imports and Data Loading: </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ken\\Documents\\KenP\\Applications-DataScience\\SpringboardCourseWork\\CapstoneProject2Repository\\09 PetfindersData\\TrainingData\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%cd C:\\Users\\Ken\\Documents\\KenP\\Applications-DataScience\\SpringboardCourseWork\\CapstoneProject2Repository\\09 PetfindersData\\TrainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the csv file\n",
    "\n",
    "dfi = pd.read_csv('milestonereport2_petdata_withnooutliers.csv',index_col=0)\n",
    "\n",
    "#remove the rows with no description \n",
    "dfi = dfi[pd.notnull(dfi.Description)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  NLP using Word2Vec and XGBoost: </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe of pet description feature\n",
    "dfd = dfi[['Description','AdoptionSpeed']]\n",
    "dfd.columns = ['description', 'adoptionspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>adoptionspeed</th>\n",
       "      <th>tokenized_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milo went missing after a week with her new ad...</td>\n",
       "      <td>3</td>\n",
       "      <td>[milo, went, missing, after, a, week, with, he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  adoptionspeed  \\\n",
       "0  Milo went missing after a week with her new ad...              3   \n",
       "\n",
       "                                      tokenized_desc  \n",
       "0  [milo, went, missing, after, a, week, with, he...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize and lemmatize the description data\n",
    "mylist = []\n",
    "for index, row in dfd.iterrows():\n",
    "    \n",
    "    #mylist = row[0]\n",
    " \n",
    "    #split sentence into words\n",
    "    tokens = nltk.word_tokenize(str(row[0]))\n",
    "    \n",
    "    #remove all tokens that are not alphabetic\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    #convert the tokens to lowercase\n",
    "    wordslc = [word.lower() for word in words]\n",
    "    \n",
    "    mylist.append(wordslc)\n",
    "\n",
    "\n",
    "#print(wordslc)\n",
    "dfd['tokenized_desc'] = mylist\n",
    "dfd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>adoptionspeed</th>\n",
       "      <th>tokenized_desc</th>\n",
       "      <th>tokenized_desc_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milo went missing after a week with her new ad...</td>\n",
       "      <td>3</td>\n",
       "      <td>[milo, went, missing, after, a, week, with, he...</td>\n",
       "      <td>'milo', 'went', 'missing', 'after', 'a', 'week...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  adoptionspeed  \\\n",
       "0  Milo went missing after a week with her new ad...              3   \n",
       "\n",
       "                                      tokenized_desc  \\\n",
       "0  [milo, went, missing, after, a, week, with, he...   \n",
       "\n",
       "                               tokenized_desc_string  \n",
       "0  'milo', 'went', 'missing', 'after', 'a', 'week...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert tokenized desc from list to string\n",
    "dfd['tokenized_desc_string'] = str(mylist).strip('[]')\n",
    "dfd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(dfd['description'])\n",
    "\n",
    "train_description = count_vect.transform(dfd['description'].values)\n",
    "\n",
    "X = train_description\n",
    "Y = dfd['adoptionspeed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a training and test data set\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train_nlp, X_test_nlp, Y_train_nlp, Y_test_nlp = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost: Fit the model using default values\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train_nlp,Y_train_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost: Predict the labels of the test set based on default values\n",
    "Y_pred_nlp = model.predict(X_test_nlp)\n",
    "\n",
    "Y_pred_proba_nlp = model.predict_proba(X_test_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT FOR DEFAULT VALUES\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.01      0.03       149\n",
      "          1       0.38      0.08      0.14      1022\n",
      "          2       0.32      0.38      0.35      1291\n",
      "          3       0.40      0.11      0.17      1092\n",
      "          4       0.35      0.72      0.47      1385\n",
      "\n",
      "avg / total       0.37      0.35      0.29      4939\n",
      "\n",
      "\n",
      "ACCURACY SCORE FOR DEFAULT VALUES\n",
      "0.34561652156306943\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT FOR DEFAULT VALUES')\n",
    "print(classification_report(Y_test_nlp, Y_pred_nlp))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACCURACY SCORE FOR DEFAULT VALUES')\n",
    "print(accuracy_score(Y_test_nlp,Y_pred_nlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Run the 20 Features (non-NLP) using XGBoost with best parameters identified in Milestone Report Part 2b: </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "0     1    2       0      26       2       2       0       0             2   \n",
       "\n",
       "   FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  Fee  State  \\\n",
       "0          1           1         1           2       1         1    0  41326   \n",
       "\n",
       "   VideoAmt  PhotoAmt  AdoptionSpeed  \n",
       "0         0         3              3  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the columns that are not needed for machine learning\n",
    "dfm = dfi.drop(['Name','RescuerID','Description','PetID'],axis=1)\n",
    "dfm.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the array\n",
    "array = dfm.values\n",
    "X = array[:,0:19]\n",
    "Y = array[:,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a training and test data set\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train_nonnlp, X_test_nonnlp, Y_train_nonnlp, Y_test_nonnlp = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.5,\n",
       "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_rate=0, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost: Fit the model using best hyper parameter tuning results from Part 2b\n",
    "model = XGBClassifier(colsample_bylevel = 0.5, colsample_bytree = 0.5, learning_rate = 0.1, max_depth = 6,\n",
    "                      min_child_rate = 0, subsample = 1)\n",
    "                      \n",
    "model.fit(X_train_nonnlp,Y_train_nonnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost: Predict the labels of the test set\n",
    "Y_pred_nonnlp = model.predict(X_test_nonnlp)\n",
    "\n",
    "Y_pred_proba_nonnlp = model.predict_proba(X_test_nonnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.03       149\n",
      "          1       0.38      0.33      0.35      1022\n",
      "          2       0.34      0.44      0.38      1291\n",
      "          3       0.39      0.18      0.24      1092\n",
      "          4       0.48      0.65      0.55      1385\n",
      "\n",
      "avg / total       0.40      0.40      0.38      4939\n",
      "\n",
      "\n",
      "ACCURACY SCORE\n",
      "0.4041303907673618\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT')\n",
    "print(classification_report(Y_test_nonnlp, Y_pred_nonnlp))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACCURACY SCORE')\n",
    "print(accuracy_score(Y_test_nonnlp,Y_pred_nonnlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Stacking Model: Create an ensemble model that combines the NLP model with the non-NLP (20 Features) model </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstmodel_nlp_predicted</th>\n",
       "      <th>firstmodel_nonnlp_predicted</th>\n",
       "      <th>firstmodel_Y_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstmodel_nlp_predicted  firstmodel_nonnlp_predicted  firstmodel_Y_values\n",
       "0                         4                            4                    4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a data frame of the first models nlp and nonnlp predicted results.  Then transpose it.\n",
    "df_smf = pd.DataFrame([Y_pred_nlp, Y_pred_nonnlp, Y_test_nlp]).transpose()\n",
    "\n",
    "df_smf.columns = ['firstmodel_nlp_predicted','firstmodel_nonnlp_predicted', 'firstmodel_Y_values']\n",
    "\n",
    "df_smf.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the array for the stacked model\n",
    "array = df_smf.values\n",
    "X = array[:,0:1]\n",
    "Y = array[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a train and test dataset to use on the stacked model\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train_stacked, X_test_stacked, Y_train_stacked, Y_test_stacked = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost: Fit the model\n",
    "model = XGBClassifier()\n",
    "                      \n",
    "model.fit(X_train_stacked,Y_train_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost: Predict the labels of the test set\n",
    "Y_pred_stacked = model.predict(X_test_stacked)\n",
    "\n",
    "Y_pred_proba_stacked = model.predict_proba(X_test_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.00      0.00      0.00       285\n",
      "          2       0.41      0.46      0.44       544\n",
      "          3       0.37      0.21      0.27       183\n",
      "          4       0.46      0.69      0.56       616\n",
      "\n",
      "avg / total       0.36      0.44      0.39      1630\n",
      "\n",
      "\n",
      "ACCURACY SCORE\n",
      "0.4392638036809816\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT')\n",
    "print(classification_report(Y_test_stacked, Y_pred_stacked))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACCURACY SCORE')\n",
    "print(accuracy_score(Y_test_stacked,Y_pred_stacked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
