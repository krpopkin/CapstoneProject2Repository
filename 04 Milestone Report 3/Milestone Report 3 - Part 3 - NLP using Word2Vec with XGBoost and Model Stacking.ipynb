{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook \n",
    "\n",
    "#### Feature: Description\n",
    "\n",
    "This notebook employs Word2Vec with CountVectorizer to create a training and test dataset of the pet description field.  Then the datasets are used in the XGBoost algorithm to create an adoption model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Feature Description: </I> The \"Description\" data is a profile write-up for each pet.\n",
    "     <br>\n",
    "    <I> Source: </I> https://www.kaggle.com/c/petfinder-adoption-prediction/data  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Predictor (Adoption Speed) Description: </I> \n",
    "\n",
    "Contestants are required to predict this value. The value is determined by how quickly, if at all, a pet is adopted.   \n",
    "<br> \n",
    "The values are determined in the following way:   \n",
    "0 - Pet was adopted on the same day as it was listed.    \n",
    "1 - Pet was adopted between 1 and 7 days (1st week) after being listed.    \n",
    "2 - Pet was adopted between 8 and 30 days (1st month) after being listed.    \n",
    "3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.    \n",
    "4 - No adoption after 100 days of being listed.    \n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Imports and Data Loading: </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ken\\Documents\\KenP\\Applications-DataScience\\SpringboardCourseWork\\CapstoneProject2Repository\\09 PetfindersData\\TrainingData\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%cd C:\\Users\\Ken\\Documents\\KenP\\Applications-DataScience\\SpringboardCourseWork\\CapstoneProject2Repository\\09 PetfindersData\\TrainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the csv file\n",
    "\n",
    "dfi = pd.read_csv('milestonereport2_petdata_withnooutliers.csv',index_col=0)\n",
    "\n",
    "#remove the rows with no description \n",
    "dfi = dfi[pd.notnull(dfi.Description)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  NLP using Word2Vec and XGBoost: </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe of pet description feature\n",
    "dfd = dfi[['Description','AdoptionSpeed']]\n",
    "dfd.columns = ['description', 'adoptionspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>adoptionspeed</th>\n",
       "      <th>tokenized_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milo went missing after a week with her new ad...</td>\n",
       "      <td>3</td>\n",
       "      <td>[milo, went, missing, after, a, week, with, he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  adoptionspeed  \\\n",
       "0  Milo went missing after a week with her new ad...              3   \n",
       "\n",
       "                                      tokenized_desc  \n",
       "0  [milo, went, missing, after, a, week, with, he...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize and lemmatize the description data\n",
    "mylist = []\n",
    "for index, row in dfd.iterrows():\n",
    "    \n",
    "    #mylist = row[0]\n",
    " \n",
    "    #split sentence into words\n",
    "    tokens = nltk.word_tokenize(str(row[0]))\n",
    "    \n",
    "    #remove all tokens that are not alphabetic\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    #convert the tokens to lowercase\n",
    "    wordslc = [word.lower() for word in words]\n",
    "    \n",
    "    mylist.append(wordslc)\n",
    "\n",
    "\n",
    "#print(wordslc)\n",
    "dfd['tokenized_desc'] = mylist\n",
    "dfd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>adoptionspeed</th>\n",
       "      <th>tokenized_desc</th>\n",
       "      <th>tokenized_desc_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milo went missing after a week with her new ad...</td>\n",
       "      <td>3</td>\n",
       "      <td>[milo, went, missing, after, a, week, with, he...</td>\n",
       "      <td>'milo', 'went', 'missing', 'after', 'a', 'week...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  adoptionspeed  \\\n",
       "0  Milo went missing after a week with her new ad...              3   \n",
       "\n",
       "                                      tokenized_desc  \\\n",
       "0  [milo, went, missing, after, a, week, with, he...   \n",
       "\n",
       "                               tokenized_desc_string  \n",
       "0  'milo', 'went', 'missing', 'after', 'a', 'week...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert tokenized desc from list to string\n",
    "dfd['tokenized_desc_string'] = str(mylist).strip('[]')\n",
    "dfd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(dfd['description'])\n",
    "\n",
    "train_description = count_vect.transform(dfd['description'].values)\n",
    "\n",
    "X = train_description\n",
    "Y = dfd['adoptionspeed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a training and test data set\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train_nlp, X_test_nlp, Y_train_nlp, Y_test_nlp = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost: Fit the model using default values\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train_nlp,Y_train_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost: Predict the labels of the test set based on default values\n",
    "Y_pred_nlp = model.predict(X_test_nlp)\n",
    "\n",
    "Y_pred_proba_nlp = model.predict_proba(X_test_nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02026377, 0.1886045 , 0.24847971, 0.20768732, 0.3349647 ],\n",
       "       [0.01931206, 0.15161437, 0.24960448, 0.19871081, 0.38075832],\n",
       "       [0.01838196, 0.17959955, 0.2514307 , 0.21956421, 0.33102354],\n",
       "       ...,\n",
       "       [0.03260574, 0.17825058, 0.37323868, 0.28345072, 0.13245428],\n",
       "       [0.02515974, 0.20423631, 0.24104653, 0.18865317, 0.3409042 ],\n",
       "       [0.02815031, 0.19837828, 0.2570151 , 0.18094812, 0.33550814]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_proba_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT FOR DEFAULT VALUES\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.01      0.03       149\n",
      "          1       0.38      0.08      0.14      1022\n",
      "          2       0.32      0.38      0.35      1291\n",
      "          3       0.40      0.11      0.17      1092\n",
      "          4       0.35      0.72      0.47      1385\n",
      "\n",
      "avg / total       0.37      0.35      0.29      4939\n",
      "\n",
      "\n",
      "ACCURACY SCORE FOR DEFAULT VALUES\n",
      "0.34561652156306943\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT FOR DEFAULT VALUES')\n",
    "print(classification_report(Y_test_nlp, Y_pred_nlp))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACCURACY SCORE FOR DEFAULT VALUES')\n",
    "print(accuracy_score(Y_test_nlp,Y_pred_nlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Run the 20 Features (non-NLP) using XGBoost with best parameters identified in Milestone Report Part 2b: </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "0     1    2       0      26       2       2       0       0             2   \n",
       "\n",
       "   FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  Fee  State  \\\n",
       "0          1           1         1           2       1         1    0  41326   \n",
       "\n",
       "   VideoAmt  PhotoAmt  AdoptionSpeed  \n",
       "0         0         3              3  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the columns that are not needed for machine learning\n",
    "dfm = dfi.drop(['Name','RescuerID','Description','PetID'],axis=1)\n",
    "dfm.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the array\n",
    "array = dfm.values\n",
    "X = array[:,0:19]\n",
    "Y = array[:,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a training and test data set\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train_nonnlp, X_test_nonnlp, Y_train_nonnlp, Y_test_nonnlp = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.5,\n",
       "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_rate=0, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost: Fit the model using best hyper parameter tuning results from Part 2b\n",
    "model = XGBClassifier(colsample_bylevel = 0.5, colsample_bytree = 0.5, learning_rate = 0.1, max_depth = 6,\n",
    "                      min_child_rate = 0, subsample = 1)\n",
    "                      \n",
    "model.fit(X_train_nonnlp,Y_train_nonnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost: Predict the labels of the test set\n",
    "Y_pred_nonnlp = model.predict(X_test_nonnlp)\n",
    "\n",
    "Y_pred_proba_nonnlp = model.predict_proba(X_test_nonnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01284225, 0.08572476, 0.11942077, 0.19549891, 0.58651334],\n",
       "       [0.01596327, 0.15398237, 0.14249599, 0.17416093, 0.51339746],\n",
       "       [0.0130569 , 0.11326262, 0.23594636, 0.26745942, 0.37027466],\n",
       "       ...,\n",
       "       [0.04327947, 0.26435426, 0.2020391 , 0.43081114, 0.05951603],\n",
       "       [0.01125755, 0.09420679, 0.08018898, 0.22931793, 0.5850287 ],\n",
       "       [0.01940725, 0.3715242 , 0.3618822 , 0.14317116, 0.10401516]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_proba_nonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.03       149\n",
      "          1       0.38      0.33      0.35      1022\n",
      "          2       0.34      0.44      0.38      1291\n",
      "          3       0.39      0.18      0.24      1092\n",
      "          4       0.48      0.65      0.55      1385\n",
      "\n",
      "avg / total       0.40      0.40      0.38      4939\n",
      "\n",
      "\n",
      "ACCURACY SCORE\n",
      "0.4041303907673618\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT')\n",
    "print(classification_report(Y_test_nonnlp, Y_pred_nonnlp))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACCURACY SCORE')\n",
    "print(accuracy_score(Y_test_nonnlp,Y_pred_nonnlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Stacking Model: Create an ensemble model that combines the NLP model with the non-NLP (20 Features) model </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Run the stacked model using the Y_predict values as input  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a data frame of the first models nlp and nonnlp predicted results.  Then transpose it.\n",
    "df_smf = pd.DataFrame([Y_pred_nlp, Y_pred_nonnlp, Y_test_nlp]).transpose()\n",
    "\n",
    "df_smf.columns = ['firstmodel_nlp_predicted','firstmodel_nonnlp_predicted', 'firstmodel_Y_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the array for the stacked model using the predicted values\n",
    "array = df_smf.values\n",
    "X = array[:,0:2]\n",
    "Y = array[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a train and test dataset using the predicted values to use on the stacked model\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train_stacked, X_test_stacked, Y_train_stacked, Y_test_stacked = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost: Fit the model that uses the predicted values\n",
    "model = XGBClassifier()\n",
    "                      \n",
    "model.fit(X_train_stacked,Y_train_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost: Predict the labels of the test set for the predicted values\n",
    "Y_pred_stacked = model.predict(X_test_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        52\n",
      "          1       0.33      0.33      0.33       328\n",
      "          2       0.32      0.47      0.38       425\n",
      "          3       0.47      0.09      0.16       371\n",
      "          4       0.47      0.63      0.54       454\n",
      "\n",
      "avg / total       0.39      0.39      0.35      1630\n",
      "\n",
      "\n",
      "ACCURACY SCORE\n",
      "0.3852760736196319\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT')\n",
    "print(classification_report(Y_test_stacked, Y_pred_stacked))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACCURACY SCORE')\n",
    "print(accuracy_score(Y_test_stacked,Y_pred_stacked))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Run the stacked model using the Y_predict_proba values as input  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba1</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba2</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba3</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba4</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.085725</td>\n",
       "      <td>0.119421</td>\n",
       "      <td>0.195499</td>\n",
       "      <td>0.586513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015963</td>\n",
       "      <td>0.153982</td>\n",
       "      <td>0.142496</td>\n",
       "      <td>0.174161</td>\n",
       "      <td>0.513397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstmodel_nonnlp_predicted_proba1  firstmodel_nonnlp_predicted_proba2  \\\n",
       "0                            0.012842                            0.085725   \n",
       "1                            0.015963                            0.153982   \n",
       "\n",
       "   firstmodel_nonnlp_predicted_proba3  firstmodel_nonnlp_predicted_proba4  \\\n",
       "0                            0.119421                            0.195499   \n",
       "1                            0.142496                            0.174161   \n",
       "\n",
       "   firstmodel_nonnlp_predicted_proba5  \n",
       "0                            0.586513  \n",
       "1                            0.513397  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtain the probabilities of correct nonnlp predictions from Y_pred_proba_nlp\n",
    "df_stacked = pd.DataFrame()\n",
    "\n",
    "mainlist_nonnlp = Y_pred_proba_nonnlp.tolist()\n",
    "\n",
    "nonnlpnewlist1 = []\n",
    "nonnlpnewlist2 = []\n",
    "nonnlpnewlist3 = []\n",
    "nonnlpnewlist4 = []\n",
    "nonnlpnewlist5 = []\n",
    "\n",
    "for i,v in enumerate(mainlist_nonnlp):\n",
    "    nonnlpnewlist1.append(v[0])\n",
    "    nonnlpnewlist2.append(v[1])\n",
    "    nonnlpnewlist3.append(v[2])\n",
    "    nonnlpnewlist4.append(v[3])\n",
    "    nonnlpnewlist5.append(v[4])\n",
    "\n",
    "df_stacked['firstmodel_nonnlp_predicted_proba1'] = nonnlpnewlist1\n",
    "df_stacked['firstmodel_nonnlp_predicted_proba2'] = nonnlpnewlist2\n",
    "df_stacked['firstmodel_nonnlp_predicted_proba3'] = nonnlpnewlist3\n",
    "df_stacked['firstmodel_nonnlp_predicted_proba4'] = nonnlpnewlist4\n",
    "df_stacked['firstmodel_nonnlp_predicted_proba5'] = nonnlpnewlist5\n",
    "\n",
    "df_stacked.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba1</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba2</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba3</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba4</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba5</th>\n",
       "      <th>firstmodel_nlp_predicted_proba1</th>\n",
       "      <th>firstmodel_nlp_predicted_proba2</th>\n",
       "      <th>firstmodel_nlp_predicted_proba3</th>\n",
       "      <th>firstmodel_nlp_predicted_proba4</th>\n",
       "      <th>firstmodel_nlp_predicted_proba5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.085725</td>\n",
       "      <td>0.119421</td>\n",
       "      <td>0.195499</td>\n",
       "      <td>0.586513</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.188605</td>\n",
       "      <td>0.248480</td>\n",
       "      <td>0.207687</td>\n",
       "      <td>0.334965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015963</td>\n",
       "      <td>0.153982</td>\n",
       "      <td>0.142496</td>\n",
       "      <td>0.174161</td>\n",
       "      <td>0.513397</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>0.151614</td>\n",
       "      <td>0.249604</td>\n",
       "      <td>0.198711</td>\n",
       "      <td>0.380758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstmodel_nonnlp_predicted_proba1  firstmodel_nonnlp_predicted_proba2  \\\n",
       "0                            0.012842                            0.085725   \n",
       "1                            0.015963                            0.153982   \n",
       "\n",
       "   firstmodel_nonnlp_predicted_proba3  firstmodel_nonnlp_predicted_proba4  \\\n",
       "0                            0.119421                            0.195499   \n",
       "1                            0.142496                            0.174161   \n",
       "\n",
       "   firstmodel_nonnlp_predicted_proba5  firstmodel_nlp_predicted_proba1  \\\n",
       "0                            0.586513                         0.020264   \n",
       "1                            0.513397                         0.019312   \n",
       "\n",
       "   firstmodel_nlp_predicted_proba2  firstmodel_nlp_predicted_proba3  \\\n",
       "0                         0.188605                         0.248480   \n",
       "1                         0.151614                         0.249604   \n",
       "\n",
       "   firstmodel_nlp_predicted_proba4  firstmodel_nlp_predicted_proba5  \n",
       "0                         0.207687                         0.334965  \n",
       "1                         0.198711                         0.380758  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtain the probability of a correct nlp prediction from Y_pred_proba_nlp\n",
    "mainlist_nlp = Y_pred_proba_nlp.tolist()\n",
    "\n",
    "nlpnewlist1 = []\n",
    "nlpnewlist2 = []\n",
    "nlpnewlist3 = []\n",
    "nlpnewlist4 = []\n",
    "nlpnewlist5 = []\n",
    "\n",
    "for i,v in enumerate(mainlist_nlp):\n",
    "    nlpnewlist1.append(v[0])\n",
    "    nlpnewlist2.append(v[1])\n",
    "    nlpnewlist3.append(v[2])\n",
    "    nlpnewlist4.append(v[3])\n",
    "    nlpnewlist5.append(v[4])\n",
    "\n",
    "df_stacked['firstmodel_nlp_predicted_proba1'] = nlpnewlist1\n",
    "df_stacked['firstmodel_nlp_predicted_proba2'] = nlpnewlist2\n",
    "df_stacked['firstmodel_nlp_predicted_proba3'] = nlpnewlist3\n",
    "df_stacked['firstmodel_nlp_predicted_proba4'] = nlpnewlist4\n",
    "df_stacked['firstmodel_nlp_predicted_proba5'] = nlpnewlist5\n",
    "\n",
    "df_stacked.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba1</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba2</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba3</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba4</th>\n",
       "      <th>firstmodel_nonnlp_predicted_proba5</th>\n",
       "      <th>firstmodel_nlp_predicted_proba1</th>\n",
       "      <th>firstmodel_nlp_predicted_proba2</th>\n",
       "      <th>firstmodel_nlp_predicted_proba3</th>\n",
       "      <th>firstmodel_nlp_predicted_proba4</th>\n",
       "      <th>firstmodel_nlp_predicted_proba5</th>\n",
       "      <th>firstmodel_Y_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.085725</td>\n",
       "      <td>0.119421</td>\n",
       "      <td>0.195499</td>\n",
       "      <td>0.586513</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.188605</td>\n",
       "      <td>0.248480</td>\n",
       "      <td>0.207687</td>\n",
       "      <td>0.334965</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015963</td>\n",
       "      <td>0.153982</td>\n",
       "      <td>0.142496</td>\n",
       "      <td>0.174161</td>\n",
       "      <td>0.513397</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>0.151614</td>\n",
       "      <td>0.249604</td>\n",
       "      <td>0.198711</td>\n",
       "      <td>0.380758</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstmodel_nonnlp_predicted_proba1  firstmodel_nonnlp_predicted_proba2  \\\n",
       "0                            0.012842                            0.085725   \n",
       "1                            0.015963                            0.153982   \n",
       "\n",
       "   firstmodel_nonnlp_predicted_proba3  firstmodel_nonnlp_predicted_proba4  \\\n",
       "0                            0.119421                            0.195499   \n",
       "1                            0.142496                            0.174161   \n",
       "\n",
       "   firstmodel_nonnlp_predicted_proba5  firstmodel_nlp_predicted_proba1  \\\n",
       "0                            0.586513                         0.020264   \n",
       "1                            0.513397                         0.019312   \n",
       "\n",
       "   firstmodel_nlp_predicted_proba2  firstmodel_nlp_predicted_proba3  \\\n",
       "0                         0.188605                         0.248480   \n",
       "1                         0.151614                         0.249604   \n",
       "\n",
       "   firstmodel_nlp_predicted_proba4  firstmodel_nlp_predicted_proba5  \\\n",
       "0                         0.207687                         0.334965   \n",
       "1                         0.198711                         0.380758   \n",
       "\n",
       "   firstmodel_Y_values  \n",
       "0                    4  \n",
       "1                    2  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the Y_predict columns in stacked model dataframe and reorder the dataframe\n",
    "df_stacked['firstmodel_Y_values'] = df_smf['firstmodel_Y_values']\n",
    "\n",
    "df_stacked.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the array for the stacked model using the predict_proba values\n",
    "array = df_stacked.values\n",
    "X = array[:,0:10]\n",
    "Y = array[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a train and test dataset using the predict_proba values to use on the stacked model\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train_stacked, X_test_stacked, Y_train_stacked, Y_test_stacked = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost: Fit the model that uses the predict_proba values\n",
    "model = XGBClassifier()\n",
    "                      \n",
    "model.fit(X_train_stacked,Y_train_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost: Predict the labels of the test set for the predicted values\n",
    "Y_pred_proba_stacked = model.predict(X_test_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.25      0.02      0.04        52\n",
      "        1.0       0.35      0.42      0.38       328\n",
      "        2.0       0.37      0.39      0.38       425\n",
      "        3.0       0.49      0.17      0.25       371\n",
      "        4.0       0.48      0.69      0.56       454\n",
      "\n",
      "avg / total       0.42      0.42      0.39      1630\n",
      "\n",
      "\n",
      "ACCURACY SCORE\n",
      "0.4171779141104294\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT')\n",
    "print(classification_report(Y_test_stacked, Y_pred_proba_stacked))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACCURACY SCORE')\n",
    "print(accuracy_score(Y_test_stacked,Y_pred_proba_stacked))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
