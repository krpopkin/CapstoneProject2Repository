{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook \n",
    "\n",
    "#### Objective: Petfinder Machine Learning - Part 2b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Petfinder Machine Learning: </I> The objective for this report is to share a second round of machine learning results to build a model to predict the speed at which a pet is adopted.  In the second round the following changes to try and improve the model are applied...  \n",
    "<br>\n",
    "1.\tOutliers (pets older than 12 years old are removed from the data)   \n",
    "2.\tScalarization is applied to features where this might help the algorithms produce a better model  \n",
    "3.\tHyper-parameter tuning is applied to the algorithms  \n",
    "4.\tWord-2-Vec is applied to the Pet Description for use in NLP  \n",
    "5.\tAn ensemble combines the best performing non-NLP with the best performing NLP algorithm  \n",
    "    <br>\n",
    "The classification areas are...   \n",
    "    <br>\n",
    "0 - Pet was adopted on the same day it was listed  \n",
    "1 - Pet was adopted between 1 and 7 days (1st week) after being listed  \n",
    "2 - Pet was adopted between 8 and 30 days (1st month) after being listed  \n",
    "3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed  \n",
    "4 – No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days   \n",
    " </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Data fields: </I> For a list of the features available to predict the adoption rate visit the source data at: <br>   https://www.kaggle.com/c/petfinder-adoption-prediction/data \n",
    " </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Imports and Data Loading: </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ken\\Documents\\KenP\\Applications-DataScience\\SpringboardCourseWork\\CapstoneProject2Repository\\09 PetfindersData\\TrainingData\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%cd C:\\Users\\Ken\\Documents\\KenP\\Applications-DataScience\\SpringboardCourseWork\\CapstoneProject2Repository\\09 PetfindersData\\TrainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the csv file\n",
    "dfi = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pets with outliers included:14993\n",
      "\n",
      "Total pets with outliers deleted:14978\n",
      "\n",
      "Total pets removed: 15\n"
     ]
    }
   ],
   "source": [
    "#Remove outliers\n",
    "dfi2 = dfi[dfi.Age < (12 * 12)]\n",
    "\n",
    "print('Total pets with outliers included:' + str(dfi.Age.count()))\n",
    "print()\n",
    "print('Total pets with outliers deleted:' + str(dfi2.Age.count()))\n",
    "print()\n",
    "print('Total pets removed: ' + str(dfi.Age.count() - dfi2.Age.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the dataframe with outliers removed to a csv file for future use\n",
    "out_csv = 'milestonereport2_petdata_withnooutliers.csv'\n",
    "dfi2.to_csv(out_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "0     1    2       0      26       2       2       0       0             2   \n",
       "\n",
       "   FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  Fee  State  \\\n",
       "0          1           1         1           2       1         1    0  41326   \n",
       "\n",
       "   VideoAmt  PhotoAmt  AdoptionSpeed  \n",
       "0         0         3              3  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the columns that are not needed for machine learning\n",
    "dfm = dfi2.drop(['Name','RescuerID','Description','PetID'],axis=1)\n",
    "dfm.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Prepare to run the algorithms </B> \n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the array\n",
    "array = dfm.values\n",
    "X = array[:,0:19]\n",
    "Y = array[:,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply scaling\n",
    "X_scaled = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a training and test data set\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Hyper-Parameter Tuning for XGBoost </B>  <br> <br>\n",
    "\n",
    "<I>Approach: </I>  \n",
    "1. Use Validation Curves to identify the best value for several parameters<br>  \n",
    "2. Use GridSearchCV to combine the best parameters and identify the parameters for XGBoost that produce the best model\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> XGBoost: The parameters below were selected as the best ones to tune based on a talk by Owen Zhang at ODSC Boston 2015 titled Open Source Tools and Data Science Competitions; he summarized common parameters he uses as...  \n",
    "    <br>\n",
    " Column Sampling (colsample bytree and maybe colsample bylevel) grid searched values in the range [0.3, 0.5,1].<br>  \n",
    "\n",
    " Tree Size (max depth) grid searched values in the range [3,6, 8, 10].<br>  \n",
    "\n",
    " Learning Rate (learning rate) simplified to the ratio: [2 to 10] trees , depending on the number of trees.<br>  \n",
    "\n",
    " Min LeafWeight(min child weight) simplifed to the ratio of rare events; rare events is the percentage of rare event observations in the dataset. Try [0 or 1]<br>  \n",
    "\n",
    " Row Sampling (subsample) grid searched values in the range [0.5, 0.75, 1.0].\n",
    "\n",
    " </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> Run XGBoost using the default values \n",
    " </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost: Fit the model using default values\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost: Predict the labels of the test set based on default values\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT FOR DEFAULT VALUES\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.01      0.02       130\n",
      "          1       0.35      0.31      0.33      1001\n",
      "          2       0.34      0.43      0.38      1339\n",
      "          3       0.41      0.16      0.23      1096\n",
      "          4       0.47      0.66      0.55      1377\n",
      "\n",
      "avg / total       0.41      0.40      0.37      4943\n",
      "\n",
      "\n",
      "ACCURACY SCORE FOR DEFAULT VALUES\n",
      "0.39995953874165485\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT FOR DEFAULT VALUES')\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACCURACY SCORE FOR DEFAULT VALUES')\n",
    "print(accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Validation Curves: </I> Use validation curves to identify the best value for some of the parameters \n",
    " </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES\n",
      "[[0.43882382 0.44101159 0.43739878 0.44047323 0.43823163]\n",
      " [0.44580115 0.4421328  0.44736514 0.4486924  0.44171856]\n",
      " [0.44804386 0.44599477 0.44611935 0.45280199 0.44856787]]\n"
     ]
    }
   ],
   "source": [
    "#Column Sampling - bytree\n",
    "param_range = [0.3,0.5,1]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(), X_train, Y_train, param_name=\"colsample_bytree\", param_range=param_range,\n",
    "    cv=5, scoring=\"accuracy\", n_jobs=1)\n",
    "\n",
    "print('TRAIN SCORES')\n",
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES\n",
      "[[0.43982058 0.43876915 0.44462439 0.44171856 0.44259029]\n",
      " [0.44405682 0.44175906 0.44611935 0.4486924  0.44595268]\n",
      " [0.44804386 0.44599477 0.44611935 0.45280199 0.44856787]]\n"
     ]
    }
   ],
   "source": [
    "#Column Sampling - bylevel\n",
    "param_range = [0.3, 0.5,1]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(), X_train, Y_train, param_name=\"colsample_bylevel\", param_range=param_range,\n",
    "    cv=5, scoring=\"accuracy\", n_jobs=1)\n",
    "\n",
    "print('TRAIN SCORES')\n",
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES\n",
      "[[0.44804386 0.44599477 0.44611935 0.45280199 0.44856787]\n",
      " [0.59506604 0.58789087 0.60059798 0.61594022 0.60323786]\n",
      " [0.73361575 0.7277937  0.7436153  0.74122042 0.7237858 ]\n",
      " [0.86294543 0.8458951  0.86159213 0.84533001 0.84657534]]\n"
     ]
    }
   ],
   "source": [
    "#Max_depth\n",
    "param_range = [3,6,8,10]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(), X_train, Y_train, param_name=\"max_depth\", param_range=param_range,\n",
    "    cv=5, scoring=\"accuracy\", n_jobs=1)\n",
    "\n",
    "print('TRAIN SCORES')\n",
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES\n",
      "[[0.44804386 0.44599477 0.44611935 0.45280199 0.44856787]\n",
      " [0.52417144 0.5292139  0.5292139  0.53088418 0.53138232]\n",
      " [0.59182656 0.58577302 0.58751713 0.59825654 0.59115816]\n",
      " [0.30201844 0.27258004 0.25077862 0.28032379 0.28381071]\n",
      " [0.26339397 0.28030397 0.21502429 0.26861768 0.23138232]\n",
      " [0.21505108 0.28030397 0.20804784 0.20809465 0.22216687]]\n"
     ]
    }
   ],
   "source": [
    "#learning Rate\n",
    "param_range = [0.1,0.5,1,3,5,10]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(), X_train, Y_train, param_name=\"learning_rate\", param_range=param_range,\n",
    "    cv=5, scoring=\"accuracy\", n_jobs=1)\n",
    "\n",
    "print('TRAIN SCORES')\n",
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES\n",
      "[[0.44754548 0.44512271 0.44512271 0.45367372 0.44819427]\n",
      " [0.44804386 0.44599477 0.44611935 0.45280199 0.44856787]]\n"
     ]
    }
   ],
   "source": [
    "#Min Leaf Weight (min_child_weight)\n",
    "param_range = [0,1]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(), X_train, Y_train, param_name=\"min_child_weight\", param_range=param_range,\n",
    "    cv=5, scoring=\"accuracy\", n_jobs=1)\n",
    "\n",
    "print('TRAIN SCORES')\n",
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES\n",
      "[[0.45028657 0.45596113 0.45222374 0.45815691 0.45180573]\n",
      " [0.45041116 0.45621029 0.45010589 0.45703611 0.45603985]\n",
      " [0.44804386 0.44599477 0.44611935 0.45280199 0.44856787]]\n"
     ]
    }
   ],
   "source": [
    "#Row Sampling (subsample)\n",
    "param_range = [0.5,0.75,1]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(), X_train, Y_train, param_name=\"subsample\", param_range=param_range,\n",
    "    cv=5, scoring=\"accuracy\", n_jobs=1)\n",
    "\n",
    "print('TRAIN SCORES')\n",
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> Run XGBoost using the best value from the validation curve results \n",
    " </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=1, max_delta_step=0,\n",
       "       max_depth=10, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost: Fit the model by setting the best performing parameter from the above valiation curve results.\n",
    "model = XGBClassifier(max_depth=10,learning_rate=1,subsample=0.5)\n",
    "\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost: Predict the labels of the test set\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.18      0.09      0.12       130\n",
      "          1       0.33      0.32      0.33      1001\n",
      "          2       0.34      0.34      0.34      1339\n",
      "          3       0.31      0.29      0.30      1096\n",
      "          4       0.46      0.51      0.48      1377\n",
      "\n",
      "avg / total       0.36      0.37      0.36      4943\n",
      "\n",
      "\n",
      "ACCURACY SCORE\n",
      "0.3671859194820959\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT')\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACCURACY SCORE')\n",
    "print(accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> Run XGBoost using GridSearchCV with the same values for each parameter used in the validation curves \n",
    " </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 40.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 58.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 74.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 95.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 124.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 152.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed: 201.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6480 out of 6480 | elapsed: 219.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid result best score:\n",
      "0.40408570004982564\n",
      "\n",
      "Grid result best parameters:\n",
      "{'colsample_bylevel': 0.5, 'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_rate': 0, 'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "#Using GridSearchCV on parameters to tune\n",
    "model = XGBClassifier()\n",
    "colsample_bylevel = [0.3,0.5,1]\n",
    "colsample_bytree = [0.3,0.5,1]\n",
    "max_depth = [3,6,8,10]\n",
    "learning_rate = [0.1,0.5,1,3,5,10]\n",
    "min_child_rate = [0,1]\n",
    "subsample = [0.5,0.75,1]\n",
    "\n",
    "param_grid = dict(colsample_bylevel = colsample_bylevel, colsample_bytree=colsample_bytree,\n",
    "                  max_depth=max_depth, learning_rate=learning_rate, min_child_rate=min_child_rate, subsample=subsample)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"accuracy\", n_jobs=-1, cv=kfold,\n",
    "verbose=1)\n",
    "\n",
    "grid_result = grid_search.fit(X_train,Y_train)\n",
    "\n",
    "print('Grid result best score:')\n",
    "print(grid_result.best_score_)\n",
    "print()\n",
    "print('Grid result best parameters:')\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Hyper-Parameter Tuning for RandomForest </B>  <br> <br>\n",
    "\n",
    "<I>Approach: </I>  \n",
    "1. Use GridSearchCV to combine the best parameters and identify the parameters for XGBoost that produce the best model\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> Run Random Forest using the default values\n",
    " </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: Fit the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest: Predict the labels of the test set\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.05      0.08       130\n",
      "          1       0.33      0.38      0.35      1001\n",
      "          2       0.33      0.33      0.33      1339\n",
      "          3       0.32      0.27      0.29      1096\n",
      "          4       0.48      0.51      0.50      1377\n",
      "\n",
      "avg / total       0.36      0.37      0.37      4943\n",
      "\n",
      "\n",
      "ACCURACY SCORE\n",
      "0.370220513857981\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT')\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACCURACY SCORE')\n",
    "print(accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> Run Random Forest using GridSearchCV\n",
    " </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 55.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 80.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 109.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 142.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 180.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed: 221.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid result best score:\n",
      "0.3985052316890882\n",
      "\n",
      "Grid result best parameters:\n",
      "{'max_depth': 10, 'min_samples_leaf': 25, 'min_samples_split': 2, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "#Using GridSearchCV on Random Forest parameters to tune\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "max_depth = [10,20,30,40,50,60,70,80,90,100,110]\n",
    "\n",
    "min_samples_split = [2,5,10]\n",
    "\n",
    "min_samples_leaf = [25,50,100]\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth = max_depth, min_samples_split=min_samples_split,\n",
    "                  min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"accuracy\", n_jobs=-1, cv=kfold,\n",
    "verbose=1)\n",
    "\n",
    "grid_result = grid_search.fit(X_train,Y_train)\n",
    "\n",
    "print('Grid result best score:')\n",
    "print(grid_result.best_score_)\n",
    "print()\n",
    "print('Grid result best parameters:')\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
