{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook \n",
    "\n",
    "#### Feature: Description\n",
    "\n",
    "This notebook employs Word2Vec natural language processing (NLP) algorithm in gensim to find similarities between words on the pet's description field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Feature Description: </I> The \"Description\" data is a profile write-up for each pet.\n",
    "     <br>\n",
    "    <I> Source: </I> https://www.kaggle.com/c/petfinder-adoption-prediction/data  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> <I> Predictor (Adoption Speed) Description: </I> \n",
    "\n",
    "Contestants are required to predict this value. The value is determined by how quickly, if at all, a pet is adopted.   \n",
    "<br> \n",
    "The values are determined in the following way:   \n",
    "0 - Pet was adopted on the same day as it was listed.    \n",
    "1 - Pet was adopted between 1 and 7 days (1st week) after being listed.    \n",
    "2 - Pet was adopted between 8 and 30 days (1st month) after being listed.    \n",
    "3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.    \n",
    "4 - No adoption after 100 days of being listed.    \n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ken\\Documents\\KenP\\Applications-DataScience\\SpringboardCourseWork\\CapstoneProject2Repository\\09 PetfindersData\\TrainingData\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%cd C:\\Users\\Ken\\Documents\\KenP\\Applications-DataScience\\SpringboardCourseWork\\CapstoneProject2Repository\\09 PetfindersData\\TrainingData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Imports and Data Loading: </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the csv file\n",
    "\n",
    "dfi = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milo went missing after a week with her new ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description\n",
       "0  Milo went missing after a week with her new ad..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dataframe of pet description feature\n",
    "dfd = dfi[['Description']]\n",
    "dfd.columns = ['description']\n",
    "dfd.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<p> <B>  Tokenize and lemmatize the description data </B>  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>tokenized_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milo went missing after a week with her new ad...</td>\n",
       "      <td>[milo, went, missing, after, a, week, with, he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  Milo went missing after a week with her new ad...   \n",
       "\n",
       "                                      tokenized_desc  \n",
       "0  [milo, went, missing, after, a, week, with, he...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize and lemmatize the description data\n",
    "\n",
    "mylist = []\n",
    "for index, row in dfd.iterrows():\n",
    "    \n",
    "    #mylist = row[0]\n",
    " \n",
    "    #split sentence into words\n",
    "    tokens = nltk.word_tokenize(str(row[0]))\n",
    "    \n",
    "    #remove all tokens that are not alphabetic\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    #convert the tokens to lowercase\n",
    "    wordslc = [word.lower() for word in words]\n",
    "    \n",
    "    mylist.append(wordslc)\n",
    "\n",
    "\n",
    "#print(wordslc)\n",
    "dfd['tokenized_desc'] = mylist\n",
    "dfd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6770378, 9040180)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build vocabulary and train model\n",
    "model = gensim.models.Word2Vec(mylist, size=150, window=10, min_count=2, workers=10)\n",
    "\n",
    "model.train(mylist, total_examples=len(mylist), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 0.6178869009017944),\n",
       " ('pet', 0.5253076553344727),\n",
       " ('puppy', 0.4892923831939697),\n",
       " ('security', 0.45897799730300903),\n",
       " ('dogs', 0.44591596722602844),\n",
       " ('pup', 0.43469223380088806),\n",
       " ('doggie', 0.43293023109436035),\n",
       " ('alerting', 0.4191069006919861),\n",
       " ('watchdog', 0.3913504481315613),\n",
       " ('children', 0.3816896080970764)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find similarity\n",
    "w1 = 'dog'\n",
    "model.wv.most_similar(positive =w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6178869"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarity between two different words\n",
    "model.wv.similarity(w1='dog',w2='cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52530766"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarity between two different words\n",
    "model.wv.similarity(w1='dog',w2='pet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4153346"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarity between two different words\n",
    "model.wv.similarity(w1='cat',w2='pet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
